{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lots of centrality analysis\n",
    "goal: comparison analysis on bots' and regular users' network, to find difference as features in the future\n",
    "\n",
    "data description: for each comments, link_id is the id of the post that the comment was made in, and parent_id is the id of the comment that the comment is responding to. Subreddit is the name of the subreddit (reddit community) that the post was posted in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       author  created_utc    link_id   parent_id  score       id subreddit\n",
      "0     Inshapo   1535781736  t3_9ajgfw  t1_e56nj07      1  e57777s        de\n",
      "1  haferkeks2   1535790833  t3_9ajgfw  t1_e56ncfy      1  e57bng5        de\n",
      "2      step21   1535834519  t3_9b1w1d  t1_e50sqaf      1  e58bx5b        de\n",
      "3   huetehund   1535836066  t3_9bagae  t1_e53hn9d      1  e58djnt        de\n",
      "4   [deleted]   1535795742  t3_9bagae  t1_e564if6      1  e57drbo        de\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "user_df = pd.read_csv(\"user_comments.csv\")\n",
    "print(user_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"bot_list.txt\") as f:\n",
    "    content = f.readlines()\n",
    "bot_list = [x.strip().replace('/u/','') for x in content] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (1,4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "allFiles = glob.glob(\"bot_comments\" + \"*.csv\")\n",
    "bot_df = pd.DataFrame()\n",
    "list_ = []\n",
    "for file_ in allFiles:\n",
    "    if \"1\" in file_:\n",
    "        df = pd.read_csv(file_,index_col = None, header = None)\n",
    "    else:\n",
    "        df = pd.read_csv(file_,index_col = None, header = None)\n",
    "    list_.append(df)\n",
    "bot_df = pd.concat(list_)\n",
    "bot_df.columns = ['author', 'created_utc', 'link_id', 'parent_id', 'score', 'id','subreddit']\n",
    "bot_df = bot_df[bot_df['author'] != \"author\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### build network (regular users and bots all inside)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if user respond to a same comment, then we linked then together, build the graph\n",
    "comment_map_user = {} #comment_id, #user_name \n",
    "for index, row in user_df.iterrows():\n",
    "    comment_id = row['id']\n",
    "    comment_map_user[comment_id] = row['author']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if user respond to a same comment, then we linked then together, build the graph\n",
    "comment_map_bot = {} #comment_id, #user_name \n",
    "for index, row in bot_df.iterrows():\n",
    "    comment_id = row['id']\n",
    "    comment_map_bot[comment_id] = row['author']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_map = {} # key from user, value {key to user, value counts}\n",
    "for index, row in user_df.iterrows():\n",
    "    comment_id = row['id']\n",
    "    respond_id = row['parent_id'].split(\"_\")[1]\n",
    "    from_user = comment_map_user[comment_id]\n",
    "    if respond_id in comment_map_user:\n",
    "        to_user = comment_map_user[respond_id]\n",
    "    elif respond_id in comment_map_bot:\n",
    "        to_user = comment_map_bot[respond_id]\n",
    "    else:\n",
    "        continue\n",
    "    if from_user not in network_map:\n",
    "        network_map[from_user] = {}\n",
    "    if to_user not in network_map[from_user]:\n",
    "        network_map[from_user][to_user] = 0\n",
    "    network_map[from_user][to_user] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in bot_df.iterrows():\n",
    "    comment_id = row['id']\n",
    "    respond_id = row['parent_id'].split(\"_\")[1]\n",
    "    from_user = comment_map_bot[comment_id]\n",
    "    if respond_id in comment_map_user:\n",
    "        to_user = comment_map_user[respond_id]\n",
    "    elif respond_id in comment_map_bot:\n",
    "        to_user = comment_map_bot[respond_id]\n",
    "    else:\n",
    "        continue\n",
    "    if from_user not in network_map:\n",
    "        network_map[from_user] = {}\n",
    "    if to_user not in network_map[from_user]:\n",
    "        network_map[from_user][to_user] = 0\n",
    "    network_map[from_user][to_user] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('network.json', 'w') as fp:\n",
    "    json.dump(network_map, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "g = nx.DiGraph()\n",
    "for key, value in network_map.items():\n",
    "    from_user = key\n",
    "    for k, v in value.items():\n",
    "        to_user = k\n",
    "        weight = v\n",
    "    g.add_edge(from_user, to_user, weight = weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### degree for users and bots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_list =  user_df['author'].unique().tolist()\n",
    "degree_all = nx.degree_centrality(g)\n",
    "degree_user = {}\n",
    "degree_bot = {}\n",
    "for k, v in degree_all.items():\n",
    "    if k in user_list:\n",
    "        degree_user[k] = v\n",
    "    elif k in bot_list:\n",
    "        degree_bot[k] = v\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_list =  bot_df['author'].unique().tolist()\n",
    "degree_bot = {}\n",
    "for k, v in degree_all.items():\n",
    "    if k in bot_list:\n",
    "        degree_bot[k] = v\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('degree_bot.json', 'w') as fp:\n",
    "    json.dump(degree_bot, fp)\n",
    "fp.close()\n",
    "\n",
    "with open('degree_user.json', 'w') as fp:\n",
    "    json.dump(degree_user, fp)\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### visualization analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
